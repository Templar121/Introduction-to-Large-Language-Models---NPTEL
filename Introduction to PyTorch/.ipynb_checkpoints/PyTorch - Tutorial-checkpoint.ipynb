{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1f1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45aad18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa6e5e",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d077d",
   "metadata": {},
   "source": [
    "## 1. Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623f63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar - tensor with zero dimension\n",
    "tensor0 = torch.tensor(1)\n",
    "tensor0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3556a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor0.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b492c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector - tensor with one dimension\n",
    "tensor1 = torch.tensor([6, 8, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92705b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix - tensor with two dimensions\n",
    "tensor2 = torch.tensor(([0, 1, 7], [4, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33378a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector:\n",
      " tensor([6, 8, 0, 1, 2])\t No. of dimensions: 1\t Shape: torch.Size([5])\n",
      "\n",
      "Matrix:\n",
      " tensor([[0, 1, 7],\n",
      "        [4, 2, 4]])\t No. of dimensions: 2\t Shape: torch.Size([2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dimension and shape of a tensor\n",
    "print(f'Vector:\\n {tensor1}\\t No. of dimensions: {tensor1.ndim}\\t Shape: {tensor1.shape}\\n')\n",
    "print(f'Matrix:\\n {tensor2}\\t No. of dimensions: {tensor2.ndim}\\t Shape: {tensor2.size()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3729ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate ways\n",
    "size = (3, 4)\n",
    "tensor4 = torch.empty(size)\n",
    "tensor4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9cb4dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2782, 0.2462, 0.3170, 0.7151],\n",
       "        [0.9492, 0.7424, 0.8451, 0.1560],\n",
       "        [0.5498, 0.9105, 0.4239, 0.2150]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor5 = torch.rand(size)\n",
    "tensor5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6791ba35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor6 = torch.zeros(size)\n",
    "tensor6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b997f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor7 = torch.ones(size)\n",
    "tensor7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4d0e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9491, 0.1878]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatype of a tensor\n",
    "tensor4 = torch.rand(1,2)\n",
    "print(tensor4)\n",
    "tensor4.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e16ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6948, 0.9688]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with a specific datatype\n",
    "tensor5 = torch.rand(1, 2, dtype = torch.float16)\n",
    "print(tensor5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e16a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9491, 0.1878]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the datatype of a tensor\n",
    "tensor4.type(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5db3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 3]\n",
      " [0 4]]\n",
      "tensor([[9, 3],\n",
      "        [0, 4]], dtype=torch.int32)\n",
      "tensor([[9, 3],\n",
      "        [0, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors from a numpy array\n",
    "import numpy as np\n",
    "\n",
    "example_array = np.array([[9, 3], [0, 4]])\n",
    "tensor8 =torch.from_numpy(example_array)\n",
    "\n",
    "tensor9 = torch.tensor(example_array)\n",
    "print(example_array)\n",
    "print(tensor8)\n",
    "print(tensor9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa82c71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  9]\n",
      " [ 0 12]]\n",
      "tensor([[27,  9],\n",
      "        [ 0, 12]], dtype=torch.int32)\n",
      "tensor([[9, 3],\n",
      "        [0, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "example_array*= 3\n",
    "print(example_array)\n",
    "print(tensor8)\n",
    "print(tensor9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf7ff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crearing a tensor from another tensor\n",
    "\n",
    "tensor10 = torch.ones_like(tensor8)\n",
    "tensor10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc743f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tensor11 = torch.ones(3, 7).to(device)\n",
    "\n",
    "tensor11 = torch.zeros(3, 7, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8531ef6",
   "metadata": {},
   "source": [
    "## 2. Accessing elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d4bc857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 7],\n",
       "        [4, 2, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f18e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f520935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85281254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33464c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf0750c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "tensor2[:, 2] # this will guive us all the rows and only column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1b31e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2[0, :] # this will give us only row 0 along with all columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc7114",
   "metadata": {},
   "source": [
    "## 3. Basic Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd323bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.8585, 0.3469, 0.9472],\n",
      "        [0.2172, 0.0511, 0.9250]])\n"
     ]
    }
   ],
   "source": [
    "tensor12 = torch.ones(2, 3)\n",
    "tensor13 = torch.rand(2, 3)\n",
    "\n",
    "print(tensor12)\n",
    "print(tensor13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1f93ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8585, 1.3469, 1.9472],\n",
      "        [1.2172, 1.0511, 1.9250]])\n",
      "tensor([[0.1415, 0.6531, 0.0528],\n",
      "        [0.7828, 0.9489, 0.0750]])\n",
      "tensor([[0.8585, 0.3469, 0.9472],\n",
      "        [0.2172, 0.0511, 0.9250]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Elementwise addition\n",
    "tensor14 = tensor12 + tensor13\n",
    "# torch.add(tensor12, tensor13)\n",
    "print(tensor14)\n",
    "\n",
    "# Elementwise subtraction\n",
    "tensor15 = tensor12 - tensor13\n",
    "# torch.sub(tensor12, tensor13)\n",
    "print(tensor15)\n",
    "\n",
    "# Elementwise multiplication\n",
    "tensor16 = tensor12 * tensor13\n",
    "# torch.mul(tensor12, tensor13)\n",
    "print(tensor16)\n",
    "\n",
    "# Elementwise division\n",
    "tensor17 = tensor12 / tensor12\n",
    "# torch.div(tensor12, tensor13)\n",
    "print(tensor17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6a30",
   "metadata": {},
   "source": [
    "## 4. Manipulating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f4a2403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 2, 1, 2],\n",
       "        [0, 2, 2, 0, 0],\n",
       "        [2, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 3, (4, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d4e0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(20)\n",
    "z = x.view(-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c77e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) torch.Size([20]) torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b58d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(9)\n",
    "a = a.reshape(3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a75f099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 8, 6],\n",
       "        [2, 8, 6],\n",
       "        [3, 8, 8]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randint(0, 9, (3, 3)) ## torch.randint(low = 0, high, size)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a762e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 1, 8, 6],\n",
       "        [3, 4, 5, 2, 8, 6],\n",
       "        [6, 7, 8, 3, 8, 8]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.cat((a, b), dim = 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7e434d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8],\n",
       "        [1, 8, 6],\n",
       "        [2, 8, 6],\n",
       "        [3, 8, 8]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.cat((a, b), dim = 0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b8eb04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6fe906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 7, 3, 6, 6],\n",
       "         [8, 6, 5, 5, 6],\n",
       "         [3, 2, 1, 1, 2]],\n",
       "\n",
       "        [[6, 2, 7, 4, 3],\n",
       "         [8, 1, 5, 7, 4],\n",
       "         [3, 3, 0, 5, 6]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.randint(0, 9, (2, 3, 5))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3783e75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90ad7799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  9, 10, 10,  9],\n",
       "        [16,  7, 10, 12, 10],\n",
       "        [ 6,  5,  1,  6,  8]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d80ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 15,  9, 12, 14],\n",
       "        [17,  6, 12, 16, 13]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum(dim= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "064084bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum(dim = 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957a8a5",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0c36154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor(2.0)\n",
    "x.requires_grad, x.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a7c6956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 3 * torch.sigmoid(x) + 5\n",
    "y.requires_grad, y.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b05ca98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad = True)\n",
    "\n",
    "x.requires_grad, x.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a28dc93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.6424, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 3 * torch.sigmoid(x) + 5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ffc0071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad, y.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d33a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2db03c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x0000021219718640>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c5da1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(0.3150)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad) #dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e31d1cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.grad.zero_()\n",
    "y = 3 * torch.sigmoid(x) + 5\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1e0616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4074, 0.2376, 0.2749, 0.9183, 0.6811],\n",
       "        [0.5607, 0.9501, 0.0027, 0.1777, 0.1407]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 5, requires_grad = True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c45e850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5735, 5.2941, 5.3504, 6.7617, 6.1449],\n",
       "        [5.8751, 6.8528, 5.0027, 5.2092, 5.1605]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a * a + a + 5\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37a464a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7225, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.mean()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "925a9dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.is_leaf, b.is_leaf, c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6d8ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6619379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[0.1815, 0.1475, 0.1550, 0.2837, 0.2362],\n",
      "        [0.2121, 0.2900, 0.1005, 0.1355, 0.1281]])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad) # Before gradient computation\n",
    "c.backward()\n",
    "print(a.grad) # After gradient computation dc/da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "495a17a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f069e",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c13db400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train data # y = 5 * x + 3\n",
    "x = torch.linspace(0.0, 1.0, 15).reshape(15, 1)\n",
    "w = torch.tensor([5])\n",
    "b = torch.tensor([3])\n",
    "y = w * x + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e958f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  tensor([[-0.0503]], requires_grad=True)\n",
      "b:  tensor([[0.8294]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "w = torch.randn(size = (1, 1), requires_grad = True)\n",
    "b = torch.randn(size = (1, 1), requires_grad = True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x + b\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y) ** 2).mean()\n",
    "\n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25f2e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: w = 1.204, b = 2.834, loss = 6.471\n",
      "epoch 20: w = 1.838, b = 3.705, loss = 1.896\n",
      "epoch 30: w = 2.189, b = 4.065, loss = 0.909\n",
      "epoch 40: w = 2.409, b = 4.195, loss = 0.662\n",
      "epoch 50: w = 2.566, b = 4.222, loss = 0.571\n",
      "epoch 60: w = 2.693, b = 4.205, loss = 0.514\n",
      "epoch 70: w = 2.804, b = 4.168, loss = 0.469\n",
      "epoch 80: w = 2.905, b = 4.124, loss = 0.428\n",
      "epoch 90: w = 2.999, b = 4.078, loss = 0.391\n",
      "epoch 100: w = 3.088, b = 4.032, loss = 0.357\n",
      "epoch 110: w = 3.172, b = 3.987, loss = 0.326\n",
      "epoch 120: w = 3.253, b = 3.944, loss = 0.298\n",
      "epoch 130: w = 3.330, b = 3.902, loss = 0.273\n",
      "epoch 140: w = 3.404, b = 3.863, loss = 0.249\n",
      "epoch 150: w = 3.474, b = 3.825, loss = 0.228\n",
      "epoch 160: w = 3.542, b = 3.788, loss = 0.208\n",
      "epoch 170: w = 3.606, b = 3.754, loss = 0.190\n",
      "epoch 180: w = 3.667, b = 3.720, loss = 0.174\n"
     ]
    }
   ],
   "source": [
    "# Define hyper-parameters\n",
    "learning_rate = 0.03\n",
    "num_epochs = 180\n",
    "\n",
    "#Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    l = loss(y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        \n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch {epoch + 1}: w = {w.item() :.3f}, b = {b.item():.3f}, loss = {l.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de30c1",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff4ebbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2cc2b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIFAR10', 'CIFAR100', 'CLEVRClassification', 'CREStereo', 'Caltech101', 'Caltech256', 'CarlaStereo', 'CelebA', 'Cityscapes', 'CocoCaptions', 'CocoDetection', 'Country211', 'DTD', 'DatasetFolder', 'EMNIST', 'ETH3DStereo', 'EuroSAT', 'FER2013', 'FGVCAircraft', 'FakeData', 'FallingThingsStereo', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'Flowers102', 'FlyingChairs', 'FlyingThings3D', 'Food101', 'GTSRB', 'HD1K', 'HMDB51', 'INaturalist', 'ImageFolder', 'ImageNet', 'Imagenette', 'InStereo2k', 'KMNIST', 'Kinetics', 'Kitti', 'Kitti2012Stereo', 'Kitti2015Stereo', 'KittiFlow', 'LFWPairs', 'LFWPeople', 'LSUN', 'LSUNClass', 'MNIST', 'Middlebury2014Stereo', 'MovingMNIST', 'Omniglot', 'OxfordIIITPet', 'PCAM', 'PhotoTour', 'Places365', 'QMNIST', 'RenderedSST2', 'SBDataset', 'SBU', 'SEMEION', 'STL10', 'SUN397', 'SVHN', 'SceneFlowStereo', 'Sintel', 'SintelStereo', 'StanfordCars', 'UCF101', 'USPS', 'VOCDetection', 'VOCSegmentation', 'VisionDataset', 'WIDERFace', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_optical_flow', '_stereo_matching', 'caltech', 'celeba', 'cifar', 'cityscapes', 'clevr', 'coco', 'country211', 'dtd', 'eurosat', 'fakedata', 'fer2013', 'fgvc_aircraft', 'flickr', 'flowers102', 'folder', 'food101', 'gtsrb', 'hmdb51', 'imagenet', 'imagenette', 'inaturalist', 'kinetics', 'kitti', 'lfw', 'lsun', 'mnist', 'moving_mnist', 'omniglot', 'oxford_iiit_pet', 'pcam', 'phototour', 'places365', 'rendered_sst2', 'sbd', 'sbu', 'semeion', 'stanford_cars', 'stl10', 'sun397', 'svhn', 'ucf101', 'usps', 'utils', 'video_utils', 'vision', 'voc', 'widerface']\n"
     ]
    }
   ],
   "source": [
    "print(dir(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70579854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "hidden_size = 400\n",
    "num_epochs = 8\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "102672c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = './data',train = False, download = True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a49341ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "print(train_dataset.classes)\n",
    "print(train_dataset.data.shape)\n",
    "print(train_dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fff63ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "print(test_dataset.classes)\n",
    "print(test_dataset.data.shape)\n",
    "print(test_dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7526bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 784 # Input size = 28 * 28\n",
    "out_features = 10 # no. of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0bae6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e32ff068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = iter(train_dataloader)\n",
    "imgs, labels = next(data)\n",
    "print(imgs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# for i in range(5):\n",
    "#     plt.subplot(1, 5, i + 1)\n",
    "#     plt.imshow(imgs[i][0], cmap = 'gray')\n",
    "#     plt.xlabel(f'Label = {labels[i].item()}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "758dcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNeuralNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BasicNeuralNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer1 = nn.Linear(in_features, self.hidden_size)\n",
    "        self.layer2= nn.Linear(self.hidden_size, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = torch.relu(out)\n",
    "        out= self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "model = BasicNeuralNet(hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a32a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b23e52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0191, -0.0104,  0.0085,  ..., -0.0356, -0.0333, -0.0328],\n",
      "        [-0.0022, -0.0173,  0.0166,  ..., -0.0025, -0.0306, -0.0029],\n",
      "        [ 0.0140, -0.0006, -0.0231,  ..., -0.0154, -0.0312, -0.0223],\n",
      "        ...,\n",
      "        [ 0.0297, -0.0067,  0.0258,  ...,  0.0097, -0.0066,  0.0111],\n",
      "        [-0.0091,  0.0330,  0.0032,  ...,  0.0093, -0.0127,  0.0266],\n",
      "        [ 0.0004,  0.0122, -0.0206,  ...,  0.0176, -0.0087, -0.0266]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([ 2.4458e-02,  8.4473e-03, -1.9365e-02, -9.8366e-03,  3.4209e-02,\n",
      "         3.5538e-02, -4.2835e-03,  3.3435e-03,  2.2688e-02, -2.4025e-02,\n",
      "        -3.0502e-02,  7.6866e-03,  1.4917e-02, -1.4436e-02, -2.7291e-02,\n",
      "         1.5776e-02,  3.3038e-02, -4.6843e-03, -1.9234e-03,  1.9936e-02,\n",
      "         4.3431e-03, -2.1976e-02, -2.7865e-02,  3.1759e-02,  3.4590e-02,\n",
      "         2.2292e-02, -7.5622e-03, -1.2102e-02, -9.9585e-03, -2.4771e-02,\n",
      "         3.3942e-03,  1.7069e-02,  9.9901e-03, -3.4927e-02, -2.9957e-03,\n",
      "        -4.2090e-03,  1.4971e-02,  3.4664e-02, -4.9297e-03,  9.7175e-03,\n",
      "         3.0150e-03,  6.4483e-03,  5.4518e-03, -2.1861e-02,  1.3878e-02,\n",
      "         1.5912e-02,  2.0206e-02, -6.3097e-03, -1.6257e-02,  1.3827e-02,\n",
      "        -2.1865e-02,  2.1166e-02, -2.8219e-03, -8.0901e-03,  2.1861e-02,\n",
      "         1.2334e-02,  3.4233e-02,  2.2391e-02,  2.9764e-02,  2.0729e-02,\n",
      "        -4.5431e-03, -3.2318e-02, -4.0444e-03,  4.6457e-04,  1.2229e-02,\n",
      "        -1.6216e-02, -2.0307e-02, -1.3128e-02, -8.6410e-03, -3.1455e-02,\n",
      "         2.7442e-02, -2.3193e-02, -5.5987e-03,  3.4429e-02, -1.1911e-02,\n",
      "         3.2986e-02,  3.4160e-02,  2.6515e-02, -2.8057e-02,  1.4268e-03,\n",
      "        -1.0226e-03,  2.7054e-02,  3.0798e-03,  2.5568e-02, -1.9526e-02,\n",
      "         1.4613e-02, -2.4309e-02,  1.4111e-02, -2.4803e-02,  2.7401e-02,\n",
      "        -3.4812e-02, -2.9925e-02, -1.8730e-02, -1.3750e-02,  2.1930e-02,\n",
      "         3.4255e-03,  2.6095e-02, -2.0722e-02, -3.3085e-02,  6.9742e-03,\n",
      "        -8.5945e-03,  7.0803e-03,  1.2263e-02, -1.1543e-02,  9.5081e-03,\n",
      "        -1.5259e-02,  2.0874e-02, -2.2142e-02, -1.6283e-03,  2.9006e-02,\n",
      "        -3.3914e-02, -9.1927e-03, -1.3606e-02, -3.0307e-02,  1.3751e-02,\n",
      "         7.8036e-03, -1.5511e-02, -6.8410e-03, -8.3799e-03,  2.7287e-02,\n",
      "         2.9064e-02,  3.1504e-02,  2.5299e-02,  3.4288e-02, -1.8587e-02,\n",
      "         8.4668e-03, -2.4558e-02,  2.9088e-02, -2.7631e-02,  2.3336e-02,\n",
      "        -1.2307e-02, -3.3019e-03,  3.0446e-02,  1.2839e-02,  2.2601e-02,\n",
      "        -2.4922e-02, -2.7003e-02, -1.4891e-02,  8.6631e-03, -1.5849e-02,\n",
      "        -1.6096e-02,  2.3997e-02, -8.2962e-03, -3.2462e-02, -1.8144e-02,\n",
      "        -3.0521e-02,  8.6095e-03, -1.6130e-02,  3.1006e-02, -3.0873e-02,\n",
      "         3.3524e-02, -2.3825e-02,  7.5754e-03,  2.6327e-02,  2.2369e-02,\n",
      "         1.2584e-05,  1.4256e-02,  1.0970e-02, -1.4248e-02,  5.0022e-03,\n",
      "        -5.2353e-04, -3.4331e-02, -2.3335e-02, -2.7049e-02, -2.5386e-02,\n",
      "        -2.0935e-02, -3.5678e-02,  3.4300e-02,  3.5652e-02, -2.1383e-02,\n",
      "         1.3543e-02,  1.3263e-02,  2.5351e-02, -1.8009e-02, -2.2786e-02,\n",
      "         4.5600e-03, -1.9312e-02, -1.6109e-02, -3.3729e-02, -1.4058e-02,\n",
      "        -2.9057e-02,  2.7020e-02,  3.0201e-02, -5.2262e-03,  2.1965e-02,\n",
      "         1.4236e-02,  3.3919e-02, -9.7082e-03,  1.2231e-02,  1.9505e-02,\n",
      "         2.3298e-02,  1.2228e-02,  1.4800e-02, -2.1345e-02,  3.4724e-02,\n",
      "        -2.7104e-02,  1.7245e-02, -1.2781e-02,  4.4469e-03,  3.5678e-02,\n",
      "         7.9226e-03, -1.5283e-02,  2.9200e-02,  3.3348e-02, -2.0991e-02,\n",
      "        -2.2204e-02,  1.8120e-02, -6.2212e-03,  1.0061e-02,  2.9267e-02,\n",
      "        -9.6591e-03,  3.2459e-02,  3.3645e-02, -1.4986e-02,  1.3329e-04,\n",
      "         1.8854e-02,  1.4387e-02,  2.8323e-02,  1.0015e-02, -6.5232e-03,\n",
      "        -3.3065e-02,  1.8905e-02,  4.2845e-03, -2.8745e-02, -1.1540e-02,\n",
      "         1.0194e-02,  2.8507e-02,  1.6862e-03,  1.3137e-02,  8.2780e-03,\n",
      "        -3.0053e-02,  3.5559e-03, -2.7680e-03,  4.9724e-03, -2.4937e-02,\n",
      "         2.3871e-02, -1.9737e-02, -3.1995e-02,  4.1768e-03,  7.4445e-03,\n",
      "        -6.0954e-03,  1.9111e-02,  1.1413e-03,  1.7805e-02, -3.4807e-03,\n",
      "         9.1738e-04, -3.2843e-03,  3.3961e-02,  1.9022e-02, -1.1559e-02,\n",
      "        -3.3299e-02,  7.7908e-03,  1.6264e-02,  2.4691e-02, -1.3038e-03,\n",
      "        -3.1569e-02,  2.0372e-02, -2.4506e-02, -3.4905e-02,  3.7615e-03,\n",
      "        -1.8579e-03, -1.1669e-02, -2.7741e-02, -8.9936e-03, -2.3886e-02,\n",
      "         2.4243e-02, -3.3114e-02, -3.8849e-03, -3.1997e-02,  6.5242e-03,\n",
      "         1.0961e-02,  5.7091e-03, -1.2403e-02,  2.7745e-02, -3.1500e-02,\n",
      "         2.8051e-02,  9.5815e-03, -1.5893e-02,  1.5928e-02, -3.4718e-02,\n",
      "        -3.2031e-02,  3.0561e-02, -1.3373e-02,  1.3425e-03,  3.5575e-02,\n",
      "        -2.3106e-02, -8.5491e-03,  3.5285e-02,  9.8273e-03,  2.0001e-03,\n",
      "        -2.6428e-02,  1.4631e-02, -3.2767e-02, -2.0271e-02, -1.1336e-02,\n",
      "        -3.2399e-02,  2.7706e-02,  2.1569e-02, -1.5273e-02,  2.0299e-02,\n",
      "         2.3036e-02,  1.5481e-02,  1.5265e-03,  2.8634e-02, -3.3047e-02,\n",
      "        -1.0629e-02,  2.4504e-02,  2.7383e-02, -2.6693e-02,  2.4414e-03,\n",
      "         3.4786e-02,  2.4655e-02,  5.4530e-03, -2.0702e-02, -3.4641e-02,\n",
      "        -1.2050e-02,  3.5651e-02, -1.9050e-03,  2.6538e-02, -2.0651e-02,\n",
      "         1.5043e-02,  2.0360e-02,  1.1667e-02, -6.0171e-03,  9.0541e-03,\n",
      "        -1.3749e-02,  2.3230e-02, -3.0100e-02,  1.3538e-02, -1.4840e-02,\n",
      "        -6.7238e-03,  8.0015e-03,  9.3340e-03, -2.6073e-03, -2.3619e-02,\n",
      "        -3.4375e-02,  2.8916e-03, -2.4215e-02, -1.4433e-02,  3.0407e-02,\n",
      "        -2.2420e-02, -1.4892e-03, -2.1060e-02,  4.8826e-03,  3.1128e-02,\n",
      "         2.9558e-02,  2.3635e-02, -1.5853e-03, -1.9457e-02, -2.2339e-02,\n",
      "        -2.2602e-02, -2.1214e-02, -2.7362e-02, -2.0240e-03, -2.7876e-02,\n",
      "        -3.0278e-03,  1.3295e-02, -1.0175e-03,  2.3182e-02, -3.3437e-02,\n",
      "        -1.6395e-02, -3.4078e-02,  1.4586e-02, -3.2472e-02,  2.0959e-02,\n",
      "         2.8152e-02, -2.9510e-02, -1.9024e-02,  1.6802e-02,  3.4758e-02,\n",
      "        -1.9771e-02,  1.7655e-02,  2.5885e-02, -9.6303e-03, -3.5349e-02,\n",
      "         2.8726e-02, -2.1707e-02,  2.1986e-02, -3.3697e-02, -2.4175e-02,\n",
      "        -2.7803e-02, -1.4983e-02, -3.4519e-02, -2.2193e-02, -1.7221e-02,\n",
      "        -3.5037e-02,  1.8888e-02,  2.4941e-03,  2.0737e-02, -1.5998e-03,\n",
      "        -3.2737e-02,  2.8401e-02,  2.3331e-02, -2.6445e-02,  5.9042e-03,\n",
      "        -2.2867e-02,  2.4273e-02,  3.1300e-02, -1.2171e-04, -2.4004e-02],\n",
      "       requires_grad=True)\n",
      "torch.Size([400, 784])\n",
      "torch.Size([400])\n"
     ]
    }
   ],
   "source": [
    "# First Linear Layer\n",
    "print(w1, b1)\n",
    "print(w1.shape)\n",
    "print(b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33eade60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0250, -0.0186,  0.0436,  ...,  0.0292,  0.0097, -0.0055],\n",
      "        [-0.0106, -0.0273, -0.0027,  ..., -0.0334, -0.0217, -0.0299],\n",
      "        [-0.0333,  0.0100,  0.0101,  ..., -0.0272, -0.0158, -0.0210],\n",
      "        ...,\n",
      "        [ 0.0382,  0.0094, -0.0367,  ..., -0.0483,  0.0055, -0.0150],\n",
      "        [ 0.0277, -0.0151,  0.0094,  ..., -0.0213, -0.0403, -0.0445],\n",
      "        [ 0.0415, -0.0298,  0.0416,  ...,  0.0410, -0.0203, -0.0103]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0165, -0.0140,  0.0107,  0.0414, -0.0411, -0.0084,  0.0361, -0.0178,\n",
      "        -0.0399,  0.0463], requires_grad=True)\n",
      "torch.Size([10, 400])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Second Linear layer\n",
    "print(w2, b2)\n",
    "print(w2.shape)\n",
    "print(b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6fd7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50a45b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0/1875, Loss: 2.295\n",
      "Epoch 0, Step 300/1875, Loss: 2.256\n",
      "Epoch 0, Step 600/1875, Loss: 2.254\n",
      "Epoch 0, Step 900/1875, Loss: 2.249\n",
      "Epoch 0, Step 1200/1875, Loss: 2.249\n",
      "Epoch 0, Step 1500/1875, Loss: 2.301\n",
      "Epoch 0, Step 1800/1875, Loss: 2.243\n",
      "Epoch 1, Step 0/1875, Loss: 2.251\n",
      "Epoch 1, Step 300/1875, Loss: 2.271\n",
      "Epoch 1, Step 600/1875, Loss: 2.259\n",
      "Epoch 1, Step 900/1875, Loss: 2.266\n",
      "Epoch 1, Step 1200/1875, Loss: 2.273\n",
      "Epoch 1, Step 1500/1875, Loss: 2.258\n",
      "Epoch 1, Step 1800/1875, Loss: 2.256\n",
      "Epoch 2, Step 0/1875, Loss: 2.251\n",
      "Epoch 2, Step 300/1875, Loss: 2.277\n",
      "Epoch 2, Step 600/1875, Loss: 2.268\n",
      "Epoch 2, Step 900/1875, Loss: 2.252\n",
      "Epoch 2, Step 1200/1875, Loss: 2.250\n",
      "Epoch 2, Step 1500/1875, Loss: 2.273\n",
      "Epoch 2, Step 1800/1875, Loss: 2.254\n",
      "Epoch 3, Step 0/1875, Loss: 2.280\n",
      "Epoch 3, Step 300/1875, Loss: 2.260\n",
      "Epoch 3, Step 600/1875, Loss: 2.248\n",
      "Epoch 3, Step 900/1875, Loss: 2.259\n",
      "Epoch 3, Step 1200/1875, Loss: 2.249\n",
      "Epoch 3, Step 1500/1875, Loss: 2.265\n",
      "Epoch 3, Step 1800/1875, Loss: 2.256\n",
      "Epoch 4, Step 0/1875, Loss: 2.258\n",
      "Epoch 4, Step 300/1875, Loss: 2.261\n",
      "Epoch 4, Step 600/1875, Loss: 2.256\n",
      "Epoch 4, Step 900/1875, Loss: 2.250\n",
      "Epoch 4, Step 1200/1875, Loss: 2.253\n",
      "Epoch 4, Step 1500/1875, Loss: 2.256\n",
      "Epoch 4, Step 1800/1875, Loss: 2.244\n",
      "Epoch 5, Step 0/1875, Loss: 2.260\n",
      "Epoch 5, Step 300/1875, Loss: 2.261\n",
      "Epoch 5, Step 600/1875, Loss: 2.263\n",
      "Epoch 5, Step 900/1875, Loss: 2.262\n",
      "Epoch 5, Step 1200/1875, Loss: 2.263\n",
      "Epoch 5, Step 1500/1875, Loss: 2.260\n",
      "Epoch 5, Step 1800/1875, Loss: 2.254\n",
      "Epoch 6, Step 0/1875, Loss: 2.249\n",
      "Epoch 6, Step 300/1875, Loss: 2.248\n",
      "Epoch 6, Step 600/1875, Loss: 2.254\n",
      "Epoch 6, Step 900/1875, Loss: 2.255\n",
      "Epoch 6, Step 1200/1875, Loss: 2.263\n",
      "Epoch 6, Step 1500/1875, Loss: 2.259\n",
      "Epoch 6, Step 1800/1875, Loss: 2.258\n",
      "Epoch 7, Step 0/1875, Loss: 2.260\n",
      "Epoch 7, Step 300/1875, Loss: 2.251\n",
      "Epoch 7, Step 600/1875, Loss: 2.252\n",
      "Epoch 7, Step 900/1875, Loss: 2.260\n",
      "Epoch 7, Step 1200/1875, Loss: 2.264\n",
      "Epoch 7, Step 1500/1875, Loss: 2.255\n",
      "Epoch 7, Step 1800/1875, Loss: 2.259\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "total_steps = len(train_dataloader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, lables) in enumerate(train_dataloader):\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # Parameter update\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if i % 300 == 0:\n",
    "            print(f'Epoch {epoch}, Step {i}/{total_steps}, Loss: {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6dcaf8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.280000000000001 %\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    num_samples = len(test_dataloader.dataset)\n",
    "    \n",
    "    for imgs, labels in test_dataloader:\n",
    "        imgs = imgs.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    acc = correct / num_samples\n",
    "    print(f'Accuracy: {100 * acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d25f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
